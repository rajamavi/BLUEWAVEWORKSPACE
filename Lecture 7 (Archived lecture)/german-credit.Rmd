---
title: "Classification: Decision Trees and Random Forest"
output: html_notebook
author: "Vijay K. Gurbani, Ph.D., Illinois Institute of Technology"
---
#### German credit dataset with 21 variables and 1,000 records.  The dependent target is Creditability, which is 1 or 0 depending on whether a loan is to be granted or not, respectively, to a customer.  The dataset is available at  https://sites.google.com/site/pocketecoworld/german_credit.csv
#### We will classify the dataset using Decision Trees and Random Forests.

#### **If you do not have package 'randomForest' installed, make sure you install it first.**

```{r}
library(rpart)
library(caret)
library(rpart.plot)
library(randomForest)

setwd("/home/vkg/IIT/CS422/lectures/lecture-5")
set.seed(1122)

df <- read.csv("german_credit.csv", sep=",", comment.char = "#")
# Note: You can also read the file directly using a URL:
# df <- read.csv("https://sites.google.com/site/pocketecoworld/german_credit.csv")
head(df)
str(df)
```
#### Coerce the response variable to be a factor.
```{r}
df$Creditability <- as.factor(df$Creditability)
```
#### Create the training and test datasets.
```{r}
indx <- sample(1:nrow(df), 200)
train <- df[-indx, ]
test <- df[indx, ]
```
#### Let's see the distribution of the class labels in the training and testing datasets
```{r}
cat("Training dataset class label distribution")
table(train$Creditability)
cat("\nTest dataset class label distribution")
table(test$Creditability)
```

#### Let's run the Decision Tree model first
```{r}
model <- rpart(Creditability ~ ., data=train)
pred <- predict(model, test, type="class")
confusionMatrix(pred, as.factor(test$Creditability), positive='1')
```
#### Note Sensitivity, Specificity and Balanced Accuracy.  Specificity (TNR) is lower.  Why?
#### And now let's run Random Forest
```{r}
rm(model, pred)
model <- randomForest(Creditability ~ ., data=train)
pred <- predict(model, test, type="class")
confusionMatrix(pred, as.factor(test$Creditability), positive='1')
```
#### Again, note Sensitivity, Specificity and Balanced Accuracy.  This model has even lower specificity, indicating that it is not really good at finding TN instances.  However, the balanced accuracy is higher here.

#### Let's see what information the RF model contains
```{r}
print(model)
```
#### Note that (a) 500 trees were created, and (b) log_2(21) ~ 4, so about 4 features were randomly selected to do the split.  What happens if we increase those to 6 features?
```{r}
rm(model, pred)
model <- randomForest(Creditability ~ ., data=train, mtry=6)
pred <- predict(model, test, type="class")
confusionMatrix(pred, as.factor(test$Creditability), positive='1')
print(model)
```
#### A bit better.  Higher balanced accuracy, and higher specificity (TNR).  Note that RF seeds its own PRNG, so if you run the code above multiple times, you will get different measurements.

#### You can also plot the error rate against the number of trees created to see where things stabilize

```{r}
plot(model, main="Random Forest on German Credit Data")
legend("topright", colnames(model$err.rate), col=1:3, cex = 0.8, fill=1:3)
```

